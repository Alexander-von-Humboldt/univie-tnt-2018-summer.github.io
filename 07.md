---
layout: page
title: Webscraping
subtitle: Getting to know `Wget`
---

# Goals:

Introduction into webscraping, or how one can efficiently collect lots of information from the Internet .


# Software:

* `wget` (<https://www.gnu.org/software/wget/>), a free software package for retrieving files using HTTP, HTTPS, FTP and FTPS the most widely-used Internet protocols. It is a non-interactive command line tool, so it may easily be called from scripts, cron jobs, terminals without X-Windows support, etc.


# Class:

* practical example of batch scraping with `wget`
	* web-page analysis
	* extraction of links with `regular expressions`
	* modification with `regular expressions`
	* batch download

# Examples for Downloading

## Practice 1: very easy

<./files/07/articles/1860-11-12_article_01.txt>
<./files/07/articles/1860-11-12_article_02.txt>
<./files/07/articles/1860-11-12_article_03.txt>
<./files/07/articles/1860-11-12_article_04.txt>
<./files/07/articles/1860-11-12_article_05.txt>
<./files/07/articles/1860-11-12_article_06.txt>
<./files/07/articles/1860-11-12_article_07.txt>
<./files/07/articles/1860-11-12_article_08.txt>
<./files/07/articles/1860-11-12_article_09.txt>
<./files/07/articles/1860-11-12_article_10.txt>
<./files/07/articles/1860-11-12_article_11.txt>
<./files/07/articles/1860-11-12_article_12.txt>
<./files/07/articles/1860-11-12_article_13.txt>
<./files/07/articles/1860-11-12_article_14.txt>
<./files/07/articles/1860-11-12_article_15.txt>
<./files/07/articles/1860-11-12_article_16.txt>
<./files/07/articles/1860-11-12_article_17.txt>
<./files/07/articles/1860-11-12_article_18.txt>
<./files/07/articles/1860-11-12_article_19.txt>
<./files/07/articles/1860-11-12_article_20.txt>
<./files/07/articles/1860-11-12_article_21.txt>
<./files/07/articles/1860-11-12_article_22.txt>
<./files/07/articles/1860-11-12_article_23.txt>
<./files/07/articles/1860-11-12_article_24.txt>
<./files/07/articles/1860-11-12_article_25.txt>
<./files/07/articles/1860-11-12_article_26.txt>
<./files/07/articles/1860-11-12_article_27.txt>
<./files/07/articles/1860-11-12_article_28.txt>
<./files/07/articles/1860-11-12_article_29.txt>
<./files/07/articles/1860-11-12_article_30.txt>
<./files/07/articles/1860-11-12_article_31.txt>
<./files/07/articles/1860-11-12_article_32.txt>
<./files/07/articles/1860-11-12_article_33.txt>
<./files/07/articles/1860-11-12_article_34.txt>
<./files/07/articles/1860-11-12_article_35.txt>
<./files/07/articles/1860-11-12_article_36.txt>
<./files/07/articles/1860-11-12_article_37.txt>
<./files/07/articles/1860-11-12_article_38.txt>
<./files/07/articles/1860-11-12_article_39.txt>

## Practice 2: easy-ish



# Reference Materials:

* Milligan, Ian. 2012. “Automated Downloading with Wget.” Programming Historian, June. <https://programminghistorian.org/lessons/automated-downloading-with-wget>.
* Kurschinski, Kellen. 2013. “Applied Archival Downloading with Wget.” Programming Historian, September. <https://programminghistorian.org/lessons/applied-archival-downloading-with-wget>.
* Alternatively, this operation can be done with a Python script: Turkel, William J., and Adam Crymble. 2012. “Downloading Web Pages with Python.” Programming Historian, July. <https://programminghistorian.org/lessons/working-with-web-pages>.


# Homework:

1. Scraping the “Dispatch”: download all issues of “Richmond Times Dispatch” (Years 1860-1865), which are available at: <http://www.perseus.tufts.edu/hopper/collection?collection=Perseus:collection:RichTimes>)
2. Publish a step-by-step explanation of what you have done as a blogpost on your website.
3. Codecademy’s Learn Python, Unit 7-8.
4. Github: publish the confirmation screenshot as a post on your new site.
