---
layout: page
title: Webscraping
subtitle: Getting to know `Wget`
---

# Goals:

Introduction into webscraping, or how one can efficiently collect lots of information from the Internet .


# Software:

* `wget` (<https://www.gnu.org/software/wget/>), a free software package for retrieving files using HTTP, HTTPS, FTP and FTPS the most widely-used Internet protocols. It is a non-interactive command line tool, so it may easily be called from scripts, cron jobs, terminals without X-Windows support, etc.


# Class:

* practical example of batch scraping with `wget`
	* web-page analysis
	* extraction of links with `regular expressions`
	* modification with `regular expressions`
	* batch download

# Examples for Downloading

## Practice 1: very easy

* [./files/07/articles/1860-11-12_article_01.txt](1860-11-12_article_01.txt)

## Practice 2: easy-ish



# Reference Materials:

* Milligan, Ian. 2012. “Automated Downloading with Wget.” Programming Historian, June. <https://programminghistorian.org/lessons/automated-downloading-with-wget>.
* Kurschinski, Kellen. 2013. “Applied Archival Downloading with Wget.” Programming Historian, September. <https://programminghistorian.org/lessons/applied-archival-downloading-with-wget>.
* Alternatively, this operation can be done with a Python script: Turkel, William J., and Adam Crymble. 2012. “Downloading Web Pages with Python.” Programming Historian, July. <https://programminghistorian.org/lessons/working-with-web-pages>.


# Homework:

1. Scraping the “Dispatch”: download all issues of “Richmond Times Dispatch” (Years 1860-1865), which are available at: <http://www.perseus.tufts.edu/hopper/collection?collection=Perseus:collection:RichTimes>)
2. Publish a step-by-step explanation of what you have done as a blogpost on your website.
3. Codecademy’s Learn Python, Unit 7-8.
4. Github: publish the confirmation screenshot as a post on your new site.
